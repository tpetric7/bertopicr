# Reduce dimensionality of embeddings using UMAP
reduced_embeddings <- umap$UMAP(n_neighbors = 10L, n_components = 2L, min_dist = 0.0, metric = 'cosine')$fit_transform(embeddings)
visualize_documents(model = topic_model,
texts = texts_cleaned,
reduced_embeddings = reduced_embeddings,
filename = "visualize_documents", # default extension html
auto_open = FALSE) # TRUE enables output in browser
visualize_topics_over_time(model = topic_model,
# see Topic Dynamics section above
topics_over_time_model = topics_over_time,
top_n_topics = 10, # default is 20
filename = "topics_over_time") # default, html extension
classes = as.list(dataset$genre) # text types
topics_per_class = topic_model$topics_per_class(texts_cleaned, classes=classes)
visualize_topics_per_class(model = topic_model,
topics_per_class = topics_per_class,
start = 0, # default
end = 9, # default
filename = "topics_per_class", # default, html extension
auto_open = FALSE) # TRUE enables output in browser
classes = as.list(dataset$genre) # text types
topics_per_class = topic_model$topics_per_class(texts_cleaned, classes=classes)
visualize_topics_per_class(model = topic_model,
topics_per_class = topics_per_class,
start = 0, # default
end = 10, # default
filename = "topics_per_class", # default, html extension
auto_open = FALSE) # TRUE enables output in browser
devtools::build_vignettes()
devtools::build_vignettes()
devtools::build_vignettes()
quarto check()
quarto::quarto check()
installed.packages("quarto")
installed.packages("quanteda")
install.packages("quarto")
quarto::quarto_version()
devtools::build_vignettes()
quarto::quarto check
devtools::build_vignettes()
devtools::build_vignettes(quiet = FALSE)
library(usethis)
library(roxygen2)
roxygenize()
devtools::check()
roxygenize()
devtools::check()
roxygenize()
devtools::check()
roxygenize()
devtools::check()
getwd()
library(usethis)
library(roxygen2)
roxygenize()
devtools::check()
roxygenize()
devtools::check()
roxygenize()
devtools::check()
roxygenize()
devtools::check()
devtools::check()
roxygenize()
devtools::check()
library(dplyr)
library(tidyr)
library(purrr)
library(utils)
library(tibble)
library(readr)
library(tictoc)
library(htmltools)
library(arrow)
# interface with Python
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
library(bertopicr)
# Correct way to find the path
parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
# Read the parquet file using the correct path
library(arrow)
dataset <- arrow::read_parquet(parquet_path)
names(dataset)
dim(dataset)
roxygenize()
devtools::check()
# Find the path
# parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
# stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
parquet_path <- file.path("data", "spiegel_sample.parquet")
stopwords_path <- file.path("data", "all_stopwords.txt")
parquet_path
stopwords_path
dataset <- arrow::read_parquet(parquet_path)
# Find the path
# parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
# stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
parquet_path <- file.path("data", "spiegel_sample.parquet")
stopwords_path <- file.path("data", "all_stopwords.txt")
# Read the parquet file using the correct path
library(arrow)
dataset <- arrow::read_parquet(parquet_path)
# Find the path
# parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
# stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
parquet_path <- file.path("./data", "spiegel_sample.parquet")
stopwords_path <- file.path("./data", "all_stopwords.txt")
parquet_path
dataset <- arrow::read_parquet(parquet_path)
# Find the path
# parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
# stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
parquet_path <- file.path("../data", "spiegel_sample.parquet")
stopwords_path <- file.path("../data", "all_stopwords.txt")
parquet_path
dataset <- arrow::read_parquet(parquet_path)
roxygenize()
devtools::check()
roxygenize()
devtools::check()
roxygenize()
devtools::check()
# Find the path
# parquet_path <- system.file("data", "spiegel_sample.parquet", package = "bertopicr")
# stopwords_path <- system.file("data", "all_stopwords.txt", package = "bertopicr")
parquet_path <- file.path("../inst/extdata", "spiegel_sample.parquet")
# Read the parquet file using the correct path
library(arrow)
dataset <- arrow::read_parquet(parquet_path)
names(dataset)
dim(dataset)
stopwords_path <- file.path("../inst/extdata", "all_stopwords.txt")
all_stopwords <- read_lines(stopwords_path)
roxygenize()
devtools::check()
roxygenise()
devtools::check()
roxygenise()
devtools::check()
roxygenise()
devtools::check()
roxygenise()
devtools::check()
devtools::check()
devtools
devtools::build()
devtools::check()
library(bertopicr)
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
run_bertopic <- function(texts) {
library(reticulate)
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
# Initialize BERTopic model
model <- bertopic$BERTopic()
# Fit the model on the text data
topic_model <- model$fit_transform(texts)
return(topic_model)
}
# Example usage
library(bertopicr)
# Sample text data
texts <- c("This is the first document.", "This is the second document.")
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
library(bertopicr)
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
# Initialize BERTopic model
model <- bertopic$BERTopic()
# Fit the model on the text data
topic_model <- model$fit_transform(texts)
return(topic_model)
}
# Example usage
library(bertopicr)
# Sample text data
texts <- c("This is the first document.", "This is the second document.")
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
# Example usage
library(bertopicr)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.")
df <- data.frame(
doc_id = dplyr::row_number(),
text = texts
))
df <- data.frame(
doc_id = dplyr::row_number(),
text = texts
)
df <- data.frame(
doc_id = tibble::row_number(),
text = texts
)
df <- data.frame(
doc_id = tidyr::row_number(),
text = texts
)
df <- data.frame(
doc_id = dplyr::row_number(),
text = texts
)
df <- data.frame(
doc_id = dplyr::row_number(),
# text = texts
)
df <- data.frame(
# doc_id = dplyr::row_number(),
text = texts
)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.")
df <- data.frame(text = texts)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
# Initialize BERTopic model
topic_model <- bertopic$BERTopic()
# Fit the model on the text data
fit_transform <- model$fit_transform(texts)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
return(topic_model)
}
# Example usage
library(bertopicr)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.")
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
# Initialize BERTopic model
topic_model <- bertopic$BERTopic()
# Fit the model on the text data
fit_transform <- topic_model$fit_transform(texts)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
return(topic_model)
}
# Example usage
library(bertopicr)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.")
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.",
"We are watching basketball every evening on TV.",
"Football or soccer is a very popular game all around the world.",
"I like to cook fancy dishes.",
"The best steak I ever had in my life.")
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
# Sample text data
texts <- c("She likes ice-cream more than onions.",
"He has become the most value basketball player.",
"We are watching basketball every evening on TV.",
"Football or soccer is a very popular game all around the world.",
"I like to cook fancy dishes.",
"The best steak I ever had in my life.",
"Crime doesn't pay they say.",
"Would you like a cup of tea with biscuits?",
"No, thank you, I am a coffee drinker.")
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- readr::read_csv(url)
chocolate
# Sample text data
texts <- chocolate$most_memorable_characteristics
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
# Initialize BERTopic model
topic_model <- bertopic$BERTopic(calculate_probabilities = TRUE)
# Fit the model on the text data
fit_transform <- topic_model$fit_transform(texts)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
return(topic_model)
}
# Example usage
library(bertopicr)
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- readr::read_csv(url)
# Sample text data
texts <- chocolate$most_memorable_characteristics
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Import necessary Python modules
bertopic <- import("bertopic")
np <- import("numpy")
sentence_transformers <- import("sentence_transformers")
SentenceTransformer <- sentence_transformers$SentenceTransformer
embedding_model = SentenceTransformer("BAAI/bge-m3")
embeddings = embedding_model$encode(texts, show_progress_bar=TRUE)
# Initialize BERTopic model
topic_model <- bertopic$BERTopic(embedding_model = embedding_model,
calculate_probabilities = TRUE)
# Fit the model on the text data
fit_transform <- topic_model$fit_transform(texts, embeddings)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
return(topic_model)
}
# Example usage
library(bertopicr)
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- readr::read_csv(url)
# Sample text data
texts <- chocolate$most_memorable_characteristics
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
fit_transform[[1]]
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
# Import necessary Python modules
bertopic <- import("bertopic")
BERTopic <- bertopic$BERTopic
np <- import("numpy")
sentence_transformers <- import("sentence_transformers")
SentenceTransformer <- sentence_transformers$SentenceTransformer
# Embeddings
embedding_model = SentenceTransformer("BAAI/bge-m3")
embeddings = embedding_model$encode(texts, show_progress_bar=TRUE)
# Initialize BERTopic model
topic_model <- BERTopic(embedding_model = embedding_model,
calculate_probabilities = TRUE)
# Fit the model on the text data
fit_transform <- topic_model$fit_transform(texts, embeddings)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
# Example function using reticulate to load BERTopic
#' Run BERTopic on Text Data
#'
#' This function runs BERTopic on a given set of text data and returns the topic model.
#' @param texts A character vector of text documents.
#' @return A BERTopic model object.
#' @export
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
reticulate::py_config()
reticulate::py_available()
run_bertopic <- function(texts) {
library(reticulate)
use_python("c:/Users/teodo/anaconda3/envs/bertopic", required = TRUE)
# Import necessary Python modules
bertopic <- import("bertopic")
BERTopic <- bertopic$BERTopic
np <- import("numpy")
sentence_transformers <- import("sentence_transformers")
SentenceTransformer <- sentence_transformers$SentenceTransformer
# Embeddings
embedding_model = SentenceTransformer("BAAI/bge-m3")
embeddings = embedding_model$encode(texts, show_progress_bar=TRUE)
# Initialize BERTopic model
topic_model <- BERTopic(embedding_model = embedding_model,
calculate_probabilities = TRUE)
# Fit the model on the text data
fit_transform <- topic_model$fit_transform(texts, embeddings)
topics <- fit_transform[[1]]
probs <- fit_transform[[2]]
return(c(topics, probs))
}
# Example usage
library(bertopicr)
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- readr::read_csv(url)
# Sample text data
texts <- chocolate$most_memorable_characteristics
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
# Display the resulting topic model
print(topic_results)
avatar_raw <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-11/avatar.csv")
avatar_raw
# Example usage
library(bertopicr)
avatar_raw <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-11/avatar.csv")
# Sample text data
texts <- avatar_raw$full_text
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
# Example usage
library(bertopicr)
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- readr::read_csv(url)
# Sample text data
texts <- chocolate$most_memorable_characteristics
df <- data.frame(text = texts)
# Run BERTopic on the text data
topic_model <- run_bertopic(texts)
topic_results <- df |>
mutate(Topic = topics,
Probability = apply(probs, 1, max))
# Display the resulting topic model
print(topic_results)
print(topic_results)
visualize_documents(model = topic_model, texts = texts, reduced_embeddings = embeddings)
visualize_barchart(topic_model)
visualize_barchart(model = topic_model)
# Display the resulting topic model
topic_results
